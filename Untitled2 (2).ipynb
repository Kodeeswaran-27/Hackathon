{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b1ff113-1d95-4f56-bca3-0b7e627f9b74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Using cached torch-2.1.1-cp310-cp310-manylinux1_x86_64.whl (670.2 MB)\n",
      "Requirement already satisfied: typing-extensions in ./jupyter_env/lib/python3.10/site-packages (from torch) (4.8.0)\n",
      "Collecting filelock\n",
      "  Using cached filelock-3.13.1-py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: sympy in ./jupyter_env/lib/python3.10/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in ./jupyter_env/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in ./jupyter_env/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in ./jupyter_env/lib/python3.10/site-packages (from torch) (10.3.2.106)\n",
      "Collecting triton==2.1.0\n",
      "  Using cached triton-2.1.0-0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89.2 MB)\n",
      "Collecting fsspec\n",
      "  Using cached fsspec-2023.12.0-py3-none-any.whl (168 kB)\n",
      "Collecting networkx\n",
      "  Using cached networkx-3.2.1-py3-none-any.whl (1.6 MB)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in ./jupyter_env/lib/python3.10/site-packages (from torch) (2.18.1)\n",
      "Collecting nvidia-cublas-cu12==12.1.3.1\n",
      "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in ./jupyter_env/lib/python3.10/site-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in ./jupyter_env/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Collecting nvidia-cusolver-cu12==11.4.5.107\n",
      "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "Collecting nvidia-cusparse-cu12==12.1.0.106\n",
      "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "Requirement already satisfied: jinja2 in ./jupyter_env/lib/python3.10/site-packages (from torch) (3.1.2)\n",
      "Collecting nvidia-cudnn-cu12==8.9.2.26\n",
      "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in ./jupyter_env/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in ./jupyter_env/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.3.101)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./jupyter_env/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in ./jupyter_env/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n",
      "Installing collected packages: nvidia-cusparse-cu12, nvidia-cublas-cu12, networkx, fsspec, filelock, triton, nvidia-cusolver-cu12, nvidia-cudnn-cu12, torch\n",
      "Successfully installed filelock-3.13.1 fsspec-2023.12.0 networkx-3.2.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cudnn-cu12-8.9.2.26 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 torch-2.1.1 triton-2.1.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e0881cd-d5be-4226-ad15-b6b436a7ca86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting intel_extension_for_pytorch\n",
      "  Downloading intel_extension_for_pytorch-2.1.0-cp310-cp310-manylinux2014_x86_64.whl (51.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.4/51.4 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging in ./jupyter_env/lib/python3.10/site-packages (from intel_extension_for_pytorch) (23.2)\n",
      "Requirement already satisfied: psutil in ./jupyter_env/lib/python3.10/site-packages (from intel_extension_for_pytorch) (5.9.6)\n",
      "Collecting numpy\n",
      "  Downloading numpy-1.26.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: numpy, intel_extension_for_pytorch\n",
      "Successfully installed intel_extension_for_pytorch-2.1.0 numpy-1.26.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install intel_extension_for_pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37c71c49-45a6-4463-b577-61fd25ae156d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers datasets evaluate rouge_score -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "187922a3-662c-4ca7-bdca-a28f9e5f615b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting modin\n",
      "  Downloading modin-0.25.1-py3-none-any.whl (1.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.22.4 in ./jupyter_env/lib/python3.10/site-packages (from modin) (1.26.2)\n",
      "Requirement already satisfied: fsspec>=2022.05.0 in ./jupyter_env/lib/python3.10/site-packages (from modin) (2023.10.0)\n",
      "Requirement already satisfied: packaging>=21.0 in ./jupyter_env/lib/python3.10/site-packages (from modin) (23.2)\n",
      "Requirement already satisfied: psutil>=5.8.0 in ./jupyter_env/lib/python3.10/site-packages (from modin) (5.9.6)\n",
      "Requirement already satisfied: pandas<2.2,>=2.1 in ./jupyter_env/lib/python3.10/site-packages (from modin) (2.1.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in ./jupyter_env/lib/python3.10/site-packages (from pandas<2.2,>=2.1->modin) (2023.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./jupyter_env/lib/python3.10/site-packages (from pandas<2.2,>=2.1->modin) (2023.3.post1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./jupyter_env/lib/python3.10/site-packages (from pandas<2.2,>=2.1->modin) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in ./jupyter_env/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas<2.2,>=2.1->modin) (1.16.0)\n",
      "Installing collected packages: modin\n",
      "Successfully installed modin-0.25.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install modin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b3eaea8-c349-494b-87f4-47c49a6b03b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: modin[dask] in ./jupyter_env/lib/python3.10/site-packages (0.25.1)\n",
      "Requirement already satisfied: packaging>=21.0 in ./jupyter_env/lib/python3.10/site-packages (from modin[dask]) (23.2)\n",
      "Requirement already satisfied: pandas<2.2,>=2.1 in ./jupyter_env/lib/python3.10/site-packages (from modin[dask]) (2.1.3)\n",
      "Requirement already satisfied: psutil>=5.8.0 in ./jupyter_env/lib/python3.10/site-packages (from modin[dask]) (5.9.6)\n",
      "Requirement already satisfied: fsspec>=2022.05.0 in ./jupyter_env/lib/python3.10/site-packages (from modin[dask]) (2023.10.0)\n",
      "Requirement already satisfied: numpy>=1.22.4 in ./jupyter_env/lib/python3.10/site-packages (from modin[dask]) (1.26.2)\n",
      "Collecting distributed>=2.22.0\n",
      "  Downloading distributed-2023.12.0-py3-none-any.whl (997 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m997.8/997.8 KB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting dask>=2.22.0\n",
      "  Downloading dask-2023.12.0-py3-none-any.whl (1.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyyaml>=5.3.1 in ./jupyter_env/lib/python3.10/site-packages (from dask>=2.22.0->modin[dask]) (6.0.1)\n",
      "Collecting partd>=1.2.0\n",
      "  Downloading partd-1.4.1-py3-none-any.whl (18 kB)\n",
      "Collecting toolz>=0.10.0\n",
      "  Downloading toolz-0.12.0-py3-none-any.whl (55 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.8/55.8 KB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: click>=8.1 in ./jupyter_env/lib/python3.10/site-packages (from dask>=2.22.0->modin[dask]) (8.1.7)\n",
      "Collecting importlib-metadata>=4.13.0\n",
      "  Downloading importlib_metadata-7.0.0-py3-none-any.whl (23 kB)\n",
      "Collecting cloudpickle>=1.5.0\n",
      "  Downloading cloudpickle-3.0.0-py3-none-any.whl (20 kB)\n",
      "Collecting tblib>=1.6.0\n",
      "  Downloading tblib-3.0.0-py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: jinja2>=2.10.3 in ./jupyter_env/lib/python3.10/site-packages (from distributed>=2.22.0->modin[dask]) (3.1.2)\n",
      "Requirement already satisfied: urllib3>=1.24.3 in ./jupyter_env/lib/python3.10/site-packages (from distributed>=2.22.0->modin[dask]) (2.1.0)\n",
      "Collecting msgpack>=1.0.0\n",
      "  Downloading msgpack-1.0.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (530 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m530.8/530.8 KB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting locket>=1.0.0\n",
      "  Downloading locket-1.0.0-py2.py3-none-any.whl (4.4 kB)\n",
      "Collecting zict>=3.0.0\n",
      "  Downloading zict-3.0.0-py2.py3-none-any.whl (43 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.3/43.3 KB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tornado>=6.0.4 in ./jupyter_env/lib/python3.10/site-packages (from distributed>=2.22.0->modin[dask]) (6.4)\n",
      "Collecting sortedcontainers>=2.0.5\n",
      "  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
      "Requirement already satisfied: tzdata>=2022.1 in ./jupyter_env/lib/python3.10/site-packages (from pandas<2.2,>=2.1->modin[dask]) (2023.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./jupyter_env/lib/python3.10/site-packages (from pandas<2.2,>=2.1->modin[dask]) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./jupyter_env/lib/python3.10/site-packages (from pandas<2.2,>=2.1->modin[dask]) (2023.3.post1)\n",
      "Collecting zipp>=0.5\n",
      "  Downloading zipp-3.17.0-py3-none-any.whl (7.4 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./jupyter_env/lib/python3.10/site-packages (from jinja2>=2.10.3->distributed>=2.22.0->modin[dask]) (2.1.3)\n",
      "Requirement already satisfied: six>=1.5 in ./jupyter_env/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas<2.2,>=2.1->modin[dask]) (1.16.0)\n",
      "Installing collected packages: sortedcontainers, zipp, zict, toolz, tblib, msgpack, locket, cloudpickle, partd, importlib-metadata, dask, distributed\n",
      "Successfully installed cloudpickle-3.0.0 dask-2023.12.0 distributed-2023.12.0 importlib-metadata-7.0.0 locket-1.0.0 msgpack-1.0.7 partd-1.4.1 sortedcontainers-2.4.0 tblib-3.0.0 toolz-0.12.0 zict-3.0.0 zipp-3.17.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install modin[dask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87026695-4087-42ba-87f3-e9f262e82b09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openpyxl\n",
      "  Downloading openpyxl-3.1.2-py2.py3-none-any.whl (249 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m250.0/250.0 KB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting et-xmlfile\n",
      "  Downloading et_xmlfile-1.1.0-py3-none-any.whl (4.7 kB)\n",
      "Installing collected packages: et-xmlfile, openpyxl\n",
      "Successfully installed et-xmlfile-1.1.0 openpyxl-3.1.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73e4a60f-fbfc-40e6-af07-3eef6e0ec172",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.backends.mkl.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a8ba182-b638-4554-9b24-6b7a0e423e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from distributed import Client\n",
    "client = Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2823cb75-0dfa-4b42-ae33-292af17e2c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import modin.pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38610962-f245-432a-8644-16b7fbe71dbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: Parallel `read_excel` is a new feature! If you run into any problems, please visit https://github.com/modin-project/modin/issues. If you find a new issue and can't file it on GitHub, please email bug_reports@modin.org.\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel(\"IPC_Dataset.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6139b0e4-a982-4114-8184-ae1878563a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53c5e167-ebfc-46d1-bdf2-223dd21c0f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = df.to_dict('list')  # convert DataFrame to dictionary of lists\n",
    "dataset = Dataset.from_dict(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c670c16-9738-4434-8e13-023d5fbf04ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = dataset.train_test_split(test_size=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ffa00726-80d0-469b-a352-a2b5922dc04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "checkpoint = \"google/flan-t5-large\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0eb35036-f62f-43eb-84d6-0ceacd3231ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/jupyter_env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to /home/ubuntu/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "login(\"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\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0271cffd-f088-43dd-9e91-4ef770cb0e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_instruction(chapter: str, section: str):\n",
    "\treturn f\"\"\"### Instruction:\n",
    "What does {section.strip()}  about?\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e2e4364-d0f1-4971-95c3-ac93efd5c8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_instruction_dataset(data_point):\n",
    "\n",
    "    return {\n",
    "        \"chapter\": data_point[\"Chapter\"],\n",
    "        \"Section\": data_point[\"Section\"],\n",
    "        # \"Title\": data_point[\"Title\"],\n",
    "        # \"Description\": data_point[\"Description\"],\n",
    "        \"text\": format_instruction(data_point[\"Chapter\"],data_point[\"Section\"])\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d6d897b1-a7bf-4fa8-a7a5-51d3be254803",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dataset(data: Dataset):\n",
    "    return (\n",
    "        data.shuffle(seed=42)\n",
    "        .map(generate_instruction_dataset)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d4ad9f65-db8b-4a35-9d83-3fdba5232da9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|█████████████████████████| 8458/8458 [00:01<00:00, 4934.24 examples/s]\n"
     ]
    }
   ],
   "source": [
    "ds[\"train\"] = process_dataset(ds[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1daf4c3b-2fc1-4aa7-8915-3dee85b2f15e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'### Instruction:\\nWhat does Section 381  about?\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[\"train\"][\"text\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9a005331-b8be-4bc6-b3b0-e3d72d953845",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_instruction1(title: str, Description : str):\n",
    "\treturn f\"\"\"\n",
    "# {title.strip()} which describes {Description.strip()}\n",
    "# \"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f41003eb-6c66-4df2-8348-9bcd5fc57590",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_instruction_dataset1(data_point):\n",
    "\n",
    "    return {\n",
    "        \"chapter\": data_point[\"Chapter\"],\n",
    "        \"Section\": data_point[\"Section\"],\n",
    "        \"Title\": data_point[\"Title\"],\n",
    "        \"Description\": data_point[\"Description\"],\n",
    "        \"text\": format_instruction1(data_point[\"Title\"],data_point[\"Description\"])\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a5b3d210-2ae1-4ba9-bfec-738816acba00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dataset1(data: Dataset):\n",
    "    return (\n",
    "        data.shuffle(seed=42)\n",
    "        .map(generate_instruction_dataset1)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "70904e8e-7bdc-477b-adb9-896ecf7aa6e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|█████████████████████████| 8458/8458 [00:01<00:00, 4355.02 examples/s]\n"
     ]
    }
   ],
   "source": [
    "ds[\"out\"] = process_dataset1(ds[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0bdad5a3-82be-4c36-95fc-b696b01a964d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Acts against which there is no right of private defence which describes This section states that there is no right of private defence against an act which does not reasonably cause the apprehension of death or of grievous hurt, if done, or attempted to be done, by a public servant acting in good faith under colour of his office, though that act may not be strictly justifiable by law.\\n#'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[\"out\"][\"text\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "04f9c637-7484-49cb-a0ce-d9b11e840649",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds[\"title\"] = ds[\"train\"][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "057a159e-b355-4141-ae64-482eb9bf40dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds[\"res\"] = ds[\"out\"][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3c94c6f5-7419-4fe2-b2b1-cc49ad8b50e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: Distributing <class 'NoneType'> object. This may take some time.\n"
     ]
    }
   ],
   "source": [
    "dfs= pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e8f4e1fa-e08e-4519-9944-ea307cd341ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: `DataFrame.insert` for empty DataFrame is not currently supported by PandasOnDask, defaulting to pandas implementation.\n",
      "Please refer to https://modin.readthedocs.io/en/stable/supported_apis/defaulting_to_pandas.html for explanation.\n",
      "UserWarning: Distributing <class 'pandas.core.frame.DataFrame'> object. This may take some time.\n"
     ]
    }
   ],
   "source": [
    "dfs[\"title\"] = ds[\"title\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c4767b8b-e5f2-4ef6-bc74-9eb216c70deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[\"response\"] = ds[\"res\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cbd62325-a6ef-4add-ab44-8775e4d79bfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'### Instruction:\\nWhat does Section 237  about?\\n'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs[\"title\"][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b5b12774-0146-41f2-ba3e-d74eeb97806f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Aiding escape of, rescuing or harbouring such prisoner which describes This section provides that whoever knowingly aids any such prisoner in escaping from lawful custody, or harbors or conceals any such prisoner, knowing that such prisoner has escaped from lawful custody, shall be punished in the same manner as if he had been legally bound as a public servant by an oath under section 129 to keep such prisoner in safe custody.\\n#'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs[\"response\"][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f8e19560-c09c-40d3-896c-e4acc75c3896",
   "metadata": {},
   "outputs": [],
   "source": [
    "fin = Dataset.from_pandas(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "39cfb4fd-69a8-4e8a-a1bb-c62bffd9eb67",
   "metadata": {},
   "outputs": [],
   "source": [
    "finalDs= fin.train_test_split(test_size=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a9a316d4-0d1e-4585-855b-94c7de590eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocess_function(examples):\n",
    "    inputs = [doc for doc in examples[\"title\"]]\n",
    "    model_inputs = tokenizer(inputs, max_length=1024, truncation=True)\n",
    "\n",
    "    labels = tokenizer(text_target=examples[\"response\"], max_length=500, truncation=True)\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c84f2496-c688-4741-a7eb-ee1be1d9928c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|█████████████████████████| 8373/8373 [00:01<00:00, 5401.60 examples/s]\n",
      "Map: 100%|█████████████████████████████| 85/85 [00:00<00:00, 3219.80 examples/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_ds = finalDs.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e2177f0e-f4ab-4ec2-b4b4-3663fff9289a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4673126c-89d2-456d-a2ed-07e9e3d0f0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "rouge = evaluate.load(\"rouge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b02cad06-8087-4684-81e7-0e4d9d834daa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in ./jupyter_env/lib/python3.10/site-packages (4.35.2)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in ./jupyter_env/lib/python3.10/site-packages (from transformers) (0.4.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in ./jupyter_env/lib/python3.10/site-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./jupyter_env/lib/python3.10/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in ./jupyter_env/lib/python3.10/site-packages (from transformers) (0.19.4)\n",
      "Requirement already satisfied: requests in ./jupyter_env/lib/python3.10/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: filelock in ./jupyter_env/lib/python3.10/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./jupyter_env/lib/python3.10/site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in ./jupyter_env/lib/python3.10/site-packages (from transformers) (0.15.0)\n",
      "Requirement already satisfied: numpy>=1.17 in ./jupyter_env/lib/python3.10/site-packages (from transformers) (1.26.2)\n",
      "Requirement already satisfied: packaging>=20.0 in ./jupyter_env/lib/python3.10/site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./jupyter_env/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.8.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./jupyter_env/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.10.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./jupyter_env/lib/python3.10/site-packages (from requests->transformers) (2023.11.17)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./jupyter_env/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./jupyter_env/lib/python3.10/site-packages (from requests->transformers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./jupyter_env/lib/python3.10/site-packages (from requests->transformers) (2.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "906e1a7c-c44d-4f93-91a8-05d6877b0771",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    result = rouge.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
    "\n",
    "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "\n",
    "    return {k: round(v, 4) for k, v in result.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b82afd97-b05c-4ae8-b731-2a847d503bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2ce5c181-a6ba-4229-9a81-48d5eb11e9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"finalIPC\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=1e-4,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=1,\n",
    "    num_train_epochs=5,\n",
    "    predict_with_generate=True,\n",
    "    push_to_hub=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2d5e5b7b-0913-4614-b88c-f55da8d767c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_ds[\"train\"],\n",
    "    eval_dataset=tokenized_ds[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "22a6638c-8ad9-4ae2-9728-b3414acd090e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2620' max='2620' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2620/2620 3:37:26, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Rougel</th>\n",
       "      <th>Rougelsum</th>\n",
       "      <th>Gen Len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.978200</td>\n",
       "      <td>0.277054</td>\n",
       "      <td>0.123600</td>\n",
       "      <td>0.006800</td>\n",
       "      <td>0.100500</td>\n",
       "      <td>0.100400</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.350100</td>\n",
       "      <td>0.115972</td>\n",
       "      <td>0.145300</td>\n",
       "      <td>0.036900</td>\n",
       "      <td>0.113800</td>\n",
       "      <td>0.113400</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.202700</td>\n",
       "      <td>0.094556</td>\n",
       "      <td>0.178600</td>\n",
       "      <td>0.043200</td>\n",
       "      <td>0.138700</td>\n",
       "      <td>0.138400</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.156400</td>\n",
       "      <td>0.085744</td>\n",
       "      <td>0.171000</td>\n",
       "      <td>0.045100</td>\n",
       "      <td>0.161200</td>\n",
       "      <td>0.161100</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.137100</td>\n",
       "      <td>0.083118</td>\n",
       "      <td>0.185600</td>\n",
       "      <td>0.095100</td>\n",
       "      <td>0.171800</td>\n",
       "      <td>0.171700</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "2023-12-04 21:38:51,594 - absl - INFO - Using default tokenizer.\n",
      "UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "2023-12-04 22:20:53,329 - absl - INFO - Using default tokenizer.\n",
      "UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "2023-12-04 23:04:31,663 - absl - INFO - Using default tokenizer.\n",
      "UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "2023-12-04 23:49:50,059 - absl - INFO - Using default tokenizer.\n",
      "UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "2023-12-05 00:36:01,087 - absl - INFO - Using default tokenizer.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2620, training_loss=0.354235291663017, metrics={'train_runtime': 13051.4584, 'train_samples_per_second': 3.208, 'train_steps_per_second': 0.201, 'total_flos': 2542348112781312.0, 'train_loss': 0.354235291663017, 'epoch': 5.0})"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "07b69533-1910-4fbf-96fe-b1a2e9902764",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model.safetensors: 100%|███████████████████| 3.13G/3.13G [01:45<00:00, 29.6MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://huggingface.co/Bhuvanesh-Ch/finalIPC/tree/main/'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.push_to_hub()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0c82f4b1-4208-4360-915e-73088ce17f80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': \"Abettor which describes This section defines 'abettor' as a person who\"}]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "API_URL = \"https://api-inference.huggingface.co/models/Bhuvanesh-Ch/Tout\"\n",
    "headers = {\"Authorization\": \"Bearer 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\"}\n",
    "\n",
    "def query(payload):\n",
    "\tresponse = requests.post(API_URL, headers=headers, json=payload)\n",
    "\treturn response.json()\n",
    "\t\n",
    "output = query({\n",
    "\t\"inputs\": \"What does Section 10000000 from XVII about?s\",\n",
    "})\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b481171d-4697-420b-9eab-fa669107af8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'Abettor when liable to punishment for act abetted and for act done which describes'}]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ce1bb5b9-0a5e-45b9-865f-d4d5a1af2cfc",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'API_TOKEN' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[53], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrequests\u001b[39;00m\n\u001b[1;32m      3\u001b[0m API_URL \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://api-inference.huggingface.co/models/Bhuvanesh-Ch/finalIPC\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 4\u001b[0m headers \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAuthorization\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBearer \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mAPI_TOKEN\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mquery\u001b[39m(payload):\n\u001b[1;32m      7\u001b[0m \tresponse \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mpost(API_URL, headers\u001b[38;5;241m=\u001b[39mheaders, json\u001b[38;5;241m=\u001b[39mpayload)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'API_TOKEN' is not defined"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "API_URL = \"https://api-inference.huggingface.co/models/Bhuvanesh-Ch/finalIPC\"\n",
    "headers = {\"Authorization\": f\"Bearer {API_TOKEN}\"}\n",
    "\n",
    "def query(payload):\n",
    "\tresponse = requests.post(API_URL, headers=headers, json=payload)\n",
    "\treturn response.json()\n",
    "\t\n",
    "output = query({\n",
    "\t\"inputs\": \"What does Section 420 from XVII about?\",\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1acafe9e-69b5-45dc-99b3-a1d32d6e3c0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
